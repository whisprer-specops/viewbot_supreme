import time
import random
import asyncio
import logging
import aiohttp
from bs4 import BeautifulSoup
from utils.stats import StatsTracker

class MediumViewBot:
    def __init__(self, config, medium_interactor, browser_manager,
                 proxy_pool, account_manager, tor_controller=None,
                 webhook_manager=None, captcha_solver=None,
                 temp_email_service=None, user_agent_manager=None):

        self.config = config
        self.target_url = config["target_url"]
        self.use_tor = config.get("use_tor", False)
        self.use_freedium = config.get("use_freedium", False)

        self.medium_interactor = medium_interactor
        self.browser_manager = browser_manager
        self.proxy_pool = proxy_pool
        self.account_manager = account_manager
        self.tor_controller = tor_controller
        self.webhook_manager = webhook_manager
        self.captcha_solver = captcha_solver
        self.temp_email_service = temp_email_service
        self.user_agent_manager = user_agent_manager

        self.stats_interval = config.get("stats_interval", 60)
        self.stats_tracker = StatsTracker()
        self.running = False
        self.tasks = []

    async def run(self):
        self.running = True
        self.stats_tracker.create_counter("total_requests")
        self.stats_tracker.create_counter("successful_requests")
        self.stats_tracker.create_counter("failed_requests")
        self.stats_tracker.create_counter("page_loads")
        self.stats_tracker.create_counter("engagements")

        self.tasks.append(asyncio.create_task(self._report_stats_periodically()))

        for _ in range(self.config.get("max_concurrent_threads", 4)):
            self.tasks.append(asyncio.create_task(self._worker()))

        await asyncio.gather(*self.tasks)

    async def _worker(self):
        while self.running:
            proxy = self.proxy_pool.get_random_proxy() if not self.use_tor else None
            user_agent = self.user_agent_manager.get_random()

            async with self.browser_manager.setup_browser(proxy=proxy, use_tor=self.use_tor, user_agent=user_agent) as driver:
                if not driver:
                    self.stats_tracker.increment("failed_requests")
                    continue

                success = await self.medium_interactor.view_article(driver, self.target_url, self.use_freedium)
                self.stats_tracker.increment("successful_requests" if success else "failed_requests")
                if success:
                    self.stats_tracker.increment("page_loads")

                await asyncio.sleep(random.uniform(self.config["delay_between_requests"](),
                                                   self.config["delay_between_requests"]() * 1.5))

    async def _report_stats_periodically(self):
        while self.running:
            await asyncio.sleep(self.stats_interval)
            stats = self.stats_tracker.get_stats()
            logging.info(f"Current Stats: {stats}")
            if self.webhook_manager:
                self.webhook_manager.send_notification(f"Current MediumViewBot Stats: {stats}")

class AsyncViewClient:
    def __init__(self, target_url, proxy_pool, user_agent_manager, use_tor, config=None):
        self.target_url = target_url
        self.proxy_pool = proxy_pool
        self.user_agent_manager = user_agent_manager
        self.use_tor = use_tor
        self.config = config or {}

    async def extra_view_request(self, url, proxy=None):
        headers = {
            "Accept": "text/html",
            "Accept-Language": "en-US,en;q=0.5",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "User-Agent": self.user_agent_manager.get_random()
        }

        if random.random() < 0.3:
            headers["Referer"] = random.choice([
                "https://www.google.com/",
                "https://twitter.com/",
                "https://medium.com/"
            ])

        proxy_url = "http://127.0.0.1:9050" if self.use_tor else proxy
        timeout = aiohttp.ClientTimeout(total=30)

        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, headers=headers, proxy=proxy_url, ssl=False) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    asset_urls = [tag['src'] for tag in soup.find_all(src=True)]
                    for asset_url in random.sample(asset_urls, min(5, len(asset_urls))):
                        if not asset_url.startswith(('http', 'https')):
                            asset_url = f"https://medium.com{asset_url}"
                        try:
                            async with session.get(asset_url, headers=headers, proxy=proxy_url, ssl=False) as _:
                                pass
                        except:
                            pass
                    return True
                return False

async def run_view_only_mode(config, proxy_pool, user_agent_manager, tor_controller=None):
    client = AsyncViewClient(
        config["target_url"],
        proxy_pool,
        user_agent_manager,
        use_tor=config.get("use_tor", False),
        config=config
    )

    num_requests = config["requests_per_thread"]() * config["max_concurrent_threads"]
    delay_min = config["delay_between_requests"]()
    delay_max = delay_min * 1.5

    tasks = []
    for _ in range(num_requests):
        proxy = proxy_pool.get_random_proxy()
        tasks.append(client.extra_view_request(config["target_url"], proxy))
        await asyncio.sleep(random.uniform(delay_min, delay_max))

    results = await asyncio.gather(*tasks)
    success = sum(results)
    logging.info(f"View-only mode complete: Successful: {success}, Failed: {len(results) - success}")
    return success, len(results) - success
